import OpenAI from "openai";
import fs from "fs";

// the newest OpenAI model is "gpt-4o" which was released May 13, 2024. do not change this unless explicitly requested by the user
const openai = new OpenAI({ 
  apiKey: process.env.OPENAI_API_KEY,
  timeout: 30000 // 30 second timeout
});

// Test if API key is available
if (!process.env.OPENAI_API_KEY) {
  console.error("OPENAI_API_KEY environment variable is not set");
} else {
  console.log("OpenAI API key is configured");
}

export interface CommandResponse {
  success: boolean;
  content: string;
  type: 'text' | 'json';
}

// /translate command - translate text to specified language
export async function translateText(text: string, targetLanguage: string = 'English'): Promise<CommandResponse> {
  try {
    console.log(`Attempting translation: "${text}" to ${targetLanguage}`);
    
    const response = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [
        {
          role: "system",
          content: `You are a professional translator. Translate the following text to ${targetLanguage}. Only return the translated text, nothing else.`
        },
        {
          role: "user",
          content: text
        }
      ],
      max_tokens: 1000,
    });

    console.log("OpenAI response received successfully");
    return {
      success: true,
      content: response.choices[0].message.content || "Translation failed",
      type: 'text'
    };
  } catch (error: any) {
    console.error("Translation error details:", {
      message: error.message,
      status: error.status,
      code: error.code,
      type: error.type,
      error: error
    });
    
    return {
      success: false,
      content: `Translation failed: ${error.message || 'Unknown error'}`,
      type: 'text'
    };
  }
}

// /calculate command - perform mathematical calculations using JavaScript eval
export async function calculateExpression(expression: string): Promise<CommandResponse> {
  try {
    // ë³´ì•ˆì„ ìœ„í•´ í—ˆìš©ëœ ë¬¸ìë§Œ í•„í„°ë§
    const sanitizedExpression = expression.replace(/[^0-9+\-*/.() ]/g, '');
    
    if (sanitizedExpression !== expression) {
      return {
        success: false,
        content: "Invalid characters in expression. Only numbers, +, -, *, /, (, ), and spaces are allowed.",
        type: 'text'
      };
    }

    // ë¹ˆ í‘œí˜„ì‹ ì²´í¬
    if (!sanitizedExpression.trim()) {
      return {
        success: false,
        content: "Please provide a mathematical expression to calculate.",
        type: 'text'
      };
    }

    // JavaScriptì˜ evalì„ ì‚¬ìš©í•˜ì—¬ ê³„ì‚° (ë³´ì•ˆìƒ sanitizedëœ ì…ë ¥ë§Œ ì‚¬ìš©)
    const result = eval(sanitizedExpression);
    
    // ê²°ê³¼ê°€ ìœ íš¨í•œ ìˆ«ìì¸ì§€ í™•ì¸
    if (typeof result !== 'number' || isNaN(result)) {
      return {
        success: false,
        content: "Invalid mathematical expression.",
        type: 'text'
      };
    }

    // ìˆ«ì í¬ë§·íŒ… (í° ìˆ«ìëŠ” ì½¤ë§ˆ ì¶”ê°€)
    const formattedResult = result.toLocaleString();

    return {
      success: true,
      content: formattedResult,
      type: 'text'
    };
  } catch (error) {
    return {
      success: false,
      content: "Error calculating expression. Please check your syntax.",
      type: 'text'
    };
  }
}

// /summarize command - summarize text
export async function summarizeText(text: string): Promise<CommandResponse> {
  try {
    const response = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [
        {
          role: "system",
          content: "You are a text summarizer. Provide a concise summary of the following text. Keep it brief and capture the main points."
        },
        {
          role: "user",
          content: text
        }
      ],
      max_tokens: 300,
    });

    return {
      success: true,
      content: response.choices[0].message.content || "Summarization failed",
      type: 'text'
    };
  } catch (error) {
    return {
      success: false,
      content: "Summarization service unavailable",
      type: 'text'
    };
  }
}

// /vibe command - analyze sentiment/vibe of text
export async function analyzeVibe(text: string): Promise<CommandResponse> {
  try {
    const response = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [
        {
          role: "system",
          content: "You are a sentiment analyzer. Analyze the vibe/sentiment of the text and provide a rating from 1-5 stars and describe the emotional tone. Respond with JSON in this format: { 'rating': number, 'emotion': string, 'description': string }"
        },
        {
          role: "user",
          content: text
        }
      ],
      response_format: { type: "json_object" },
      max_tokens: 200,
    });

    const result = JSON.parse(response.choices[0].message.content || '{}');
    const stars = 'â­'.repeat(Math.max(1, Math.min(5, result.rating || 3)));
    
    return {
      success: true,
      content: `${stars} ${result.emotion || 'Neutral'}\n${result.description || 'Unable to analyze sentiment'}`,
      type: 'text'
    };
  } catch (error) {
    return {
      success: false,
      content: "Vibe analysis service unavailable",
      type: 'text'
    };
  }
}

// /poll command - create a poll
export async function createPoll(question: string, options: string[]): Promise<CommandResponse> {
  try {
    if (options.length < 2) {
      return {
        success: false,
        content: "Poll needs at least 2 options. Format: /poll Question? Option1,Option2,Option3",
        type: 'text'
      };
    }

    const pollData = {
      question: question.trim(),
      options: options.map((opt, index) => ({
        id: index + 1,
        text: opt.trim(),
        votes: 0
      })),
      totalVotes: 0,
      createdAt: new Date().toISOString()
    };

    return {
      success: true,
      content: JSON.stringify(pollData),
      type: 'json'
    };
  } catch (error) {
    return {
      success: false,
      content: "Failed to create poll",
      type: 'text'
    };
  }
}

// Command parser to handle different command types
export async function processCommand(commandText: string): Promise<CommandResponse> {
  const parts = commandText.trim().split(' ');
  const command = parts[0].toLowerCase();
  const args = parts.slice(1).join(' ');

  switch (command) {
    case '/translate':
      const translateParts = args.split(' to ');
      if (translateParts.length === 2) {
        return translateText(translateParts[0], translateParts[1]);
      }
      return translateText(args);

    case '/calculate':
    case '/calc':
      return calculateExpression(args);

    case '/summarize':
      return summarizeText(args);

    case '/vibe':
      return analyzeVibe(args);

    case '/poll':
      const pollParts = args.split('?');
      if (pollParts.length !== 2) {
        return {
          success: false,
          content: "Poll format: /poll Question? Option1,Option2,Option3",
          type: 'text'
        };
      }
      const question = pollParts[0] + '?';
      const options = pollParts[1].split(',').map(opt => opt.trim()).filter(opt => opt.length > 0);
      return createPoll(question, options);

    default:
      return {
        success: false,
        content: `Unknown command: ${command}\n\nAvailable commands:\n/translate [text] (to [language])\n/calculate [expression]\n/summarize [text]\n/vibe [text]\n/poll [question]? [option1,option2,option3]`,
        type: 'text'
      };
  }
}

// Audio transcription for voice messages with integrated smart suggestions
export async function transcribeAudio(filePath: string): Promise<{ 
  success: boolean, 
  transcription?: string, 
  duration?: number, 
  detectedLanguage?: string,
  confidence?: number,
  smartSuggestions?: any[],
  error?: string 
}> {
  try {
    console.log("Starting audio transcription with language detection...");
    console.log("Audio file path:", filePath);
    
    // Read file as buffer and create FormData with proper filename
    const audioBuffer = fs.readFileSync(filePath);
    console.log("Audio buffer read successfully, size:", audioBuffer.length, "bytes");
    
    // Create a Blob with proper MIME type and filename
    const audioBlob = new Blob([audioBuffer], { type: "audio/webm" });
    console.log("Audio blob created with type audio/webm");
    
    // Create FormData for OpenAI API with proper filename
    const formData = new FormData();
    formData.append("file", audioBlob, "audio.webm");
    formData.append("model", "whisper-1");
    formData.append("response_format", "verbose_json");
    
    console.log("FormData prepared for OpenAI API");
    
    // Make direct fetch request to OpenAI API
    const response = await fetch("https://api.openai.com/v1/audio/transcriptions", {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${process.env.OPENAI_API_KEY}`,
      },
      body: formData
    });
    
    if (!response.ok) {
      const errorText = await response.text();
      console.error("OpenAI API Error:", response.status, errorText);
      
      // Handle audio too short error as silent recording
      if (errorText.includes("Audio file is too short") || errorText.includes("audio_too_short")) {
        console.log("ğŸ”‡ Audio file too short, treating as silent recording");
        return {
          success: false,
          transcription: "",
          detectedLanguage: "ko",
          duration: 0,
          confidence: 0,
          error: "SILENT_RECORDING",
          smartSuggestions: []
        };
      }
      
      throw new Error(`OpenAI API Error: ${response.status} ${errorText}`);
    }
    
    const transcription = await response.json();
    console.log("Direct API call successful");

    console.log("Audio transcription completed:", {
      text: transcription.text,
      language: transcription.language,
      duration: transcription.duration
    });
    
    // Map language codes to readable names
    const languageNames: { [key: string]: string } = {
      'ko': 'í•œêµ­ì–´',
      'en': 'English', 
      'hu': 'Magyar',
      'de': 'Deutsch',
      'ja': 'æ—¥æœ¬èª',
      'zh': 'ä¸­æ–‡',
      'es': 'EspaÃ±ol',
      'fr': 'FranÃ§ais',
      'it': 'Italiano',
      'pt': 'PortuguÃªs',
      'ru': 'Ğ ÑƒÑÑĞºĞ¸Ğ¹'
    };
    
    const detectedLanguage = languageNames[transcription.language] || transcription.language;
    const transcribedText = transcription.text || "";
    
    // Check if transcription contains meaningful content
    const isEmptyOrNoise = (text: string): boolean => {
      if (!text || text.trim().length === 0) return true;
      
      // Common noise patterns and meaningless transcriptions
      const noisePatterns = [
        /^[\s.,!?]*$/,  // Only punctuation and whitespace
        /^(um|uh|ah|eh|hmm|mm|ì•„|ì–´|ìŒ|ìœ¼|ì•„ìš°|ì–´ìš°|ìŒ\.\.\.|\.\.\.)+[\s.,!?]*$/i,  // Filler sounds
        /^[\uD83C-\uDBFF\uDC00-\uDFFF]+[\s.,!?]*$/,  // Only emojis
        /^[ğŸ“¢ğŸµğŸ¤ğŸ”ŠğŸ”‡ğŸ“»]+[\s.,!?]*$/,  // Audio/sound emojis
        /thank you|ê°ì‚¬í•©ë‹ˆë‹¤|ê³ ë§ˆì›Œ|sorry|ì£„ì†¡|ë¯¸ì•ˆ/i,  // Common polite expressions that might be background audio
        /MBC ë‰´ìŠ¤.*ì…ë‹ˆë‹¤|KBS ë‰´ìŠ¤|SBS ë‰´ìŠ¤|ë‰´ìŠ¤ë°ìŠ¤í¬|ë‰´ìŠ¤ë£¸/i,  // News anchor patterns (Whisper hallucination)
        /ì•ˆë…•í•˜ì„¸ìš”.*ì…ë‹ˆë‹¤|ì—¬ëŸ¬ë¶„.*ì…ë‹ˆë‹¤|ì‹œì²­í•´.*ì£¼ì…”ì„œ/i,  // Generic formal greeting patterns
        /^(ë„¤|ì˜ˆ|ì•„|ì–´|ìŒ|ê·¸|ì €|ë­|ì ê¹|ì ì‹œ|ì–´ì„œ|ì´ì œ|ê·¸ëŸ¼|ê·¸ë˜ì„œ)[\s.,!?]*$/i  // Single Korean filler words
      ];
      
      // Check text length (very short transcriptions are likely noise)
      if (text.trim().length < 5) return true;
      
      // Check against noise patterns
      return noisePatterns.some(pattern => pattern.test(text.trim()));
    };
    
    // If transcription is empty or just noise, return cancellation response
    if (isEmptyOrNoise(transcribedText)) {
      console.log("ğŸ”‡ Voice recording contains no meaningful speech, canceling message");
      return {
        success: false,
        transcription: "",
        error: "SILENT_RECORDING", // Special error code for silent recordings
        duration: transcription.duration || 0,
        detectedLanguage,
        confidence: 0,
        smartSuggestions: []
      };
    }
    
    // Analyze transcribed text for smart suggestions using a single OpenAI call
    let smartSuggestions: any[] = [];
    if (transcribedText && transcribedText.length > 5) {
      console.log("ğŸ¤– Analyzing transcription for smart suggestions:", transcribedText);
      
      try {
        const analysisResponse = await openai.chat.completions.create({
          model: "gpt-4o", // the newest OpenAI model is "gpt-4o" which was released May 13, 2024. do not change this unless explicitly requested by the user
          messages: [
            {
              role: "system",
              content: `ë‹¹ì‹ ì€ ìŒì„± ë©”ì‹œì§€ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•´ì„œ ì‚¬ìš©ìê°€ YouTube ì˜ìƒì„ ì›í•˜ëŠ”ì§€, ë‚˜ì¤‘ì— ì•Œë¦¼ì„ ì›í•˜ëŠ”ì§€, ë˜ëŠ” ìœ„ì¹˜ë¥¼ ê³µìœ í•˜ë ¤ëŠ”ì§€ íŒŒì•…í•˜ëŠ” AIì…ë‹ˆë‹¤. 
              ì˜¤ì§ YouTube, ë‚˜ì¤‘ì—ì•Œë¦¼, ìœ„ì¹˜ê³µìœ  ê´€ë ¨ ìš”ì²­ë§Œ ê°ì§€í•˜ê³  JSONìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
              
              YouTube ê°ì§€ ì¡°ê±´:
              - ìœ íŠœë¸Œ, youtube, ì˜ìƒ, ë¹„ë””ì˜¤, ë®¤ì§ë¹„ë””ì˜¤, mv ë“±ì˜ í‚¤ì›Œë“œ
              - "ì˜ìƒ ë´ë´", "ìœ íŠœë¸Œë¡œ ê²€ìƒ‰", "[ì•„í‹°ìŠ¤íŠ¸ëª…] ì˜ìƒ" ë“±ì˜ í‘œí˜„
              
              ë‚˜ì¤‘ì—ì•Œë¦¼ ê°ì§€ ì¡°ê±´:
              - "ë‚˜ì¤‘ì— ë‹¤ì‹œ ì•Œë ¤ì¤„ê²Œ", "ì¡°ê¸ˆ ìˆë‹¤ê°€ ì—°ë½í• ê²Œ", "ì ê¹ í›„ì— ë§í• ê²Œ"
              - "ë‚˜ì¤‘ì— ì•Œë¦¼", "ë¦¬ë§ˆì¸ë”", "reminder", "ì•Œë ¤ì¤˜", "ìŠì§€ ì•Šê²Œ"
              - "5ë¶„ í›„ì—", "30ë¶„ í›„ì—", "1ì‹œê°„ í›„ì—", "ë‚´ì¼", "ì˜¤í›„ì—" ë“± ì‹œê°„ í‘œí˜„
              
              ìœ„ì¹˜ê³µìœ  ê°ì§€ ì¡°ê±´:
              - "ì£¼ì†Œ ë³´ë‚´ì¤„ê²Œ", "ìœ„ì¹˜ ë³´ë‚´ì¤„ê²Œ", "ë‚´ ìœ„ì¹˜ ì•Œë ¤ì¤„ê²Œ", "ë§µ ì°ì–´ì¤„ê²Œ"
              - "ì–´ë””ì•¼", "ì–´ë””ë¡œ ê°€ë©´ ë¼", "ì£¼ì†Œ ì•Œë ¤ì¤˜", "ìœ„ì¹˜ ì•Œë ¤ì¤˜"
              - "ë‚´ê°€ ì–´ë”” ìˆëŠ”ì§€ ì•Œë ¤ì¤„ê²Œ", "ì§€ê¸ˆ ì–´ë”” ìˆì–´", "ì—¬ê¸°ë¡œ ì™€"
              - "ê¸¸ ì•ˆë‚´", "ë‚´ë¹„ê²Œì´ì…˜", "ì§€ë„", "êµ¬ê¸€ë§µ", "ì¹´ì¹´ì˜¤ë§µ"
              
              ì‘ë‹µ í˜•ì‹:
              {
                "suggestions": [
                  {
                    "type": "youtube",
                    "keyword": "ì¶”ì¶œëœ í‚¤ì›Œë“œ",
                    "confidence": 0.9,
                    "text": "ğŸ¥ YouTubeì—ì„œ [í‚¤ì›Œë“œ] ê²€ìƒ‰í•˜ê¸°",
                    "icon": "ğŸ¥"
                  },
                  {
                    "type": "reminder",
                    "text": "â° ë‚˜ì¤‘ì— ì•Œë¦¼ ì„¤ì •í•˜ê¸°",
                    "confidence": 0.9,
                    "icon": "â°",
                    "reminderText": "ì›ë³¸ ë©”ì‹œì§€ ë‚´ìš©"
                  },
                  {
                    "type": "location",
                    "text": "ğŸ“ ìœ„ì¹˜ ê³µìœ í•˜ê¸°",
                    "confidence": 0.9,
                    "icon": "ğŸ“",
                    "requestMessage": "ì›ë³¸ ë©”ì‹œì§€ ë‚´ìš©"
                  }
                ]
              }
              
              ê´€ë ¨ì´ ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´ë¡œ ì‘ë‹µ: {"suggestions": []}
              
              YouTubeì˜ ê²½ìš° ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì •í™•íˆ ì¶”ì¶œí•˜ê³ , ë‚˜ì¤‘ì—ì•Œë¦¼ì˜ ê²½ìš° ì›ë³¸ ë©”ì‹œì§€ë¥¼ reminderTextë¡œ ì €ì¥í•˜ê³ , ìœ„ì¹˜ê³µìœ ì˜ ê²½ìš° ì›ë³¸ ë©”ì‹œì§€ë¥¼ requestMessageë¡œ ì €ì¥í•˜ì„¸ìš”.
              ë§¤ì¹­ë˜ëŠ” ê²ƒì´ ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´ì„ ë°˜í™˜í•˜ì„¸ìš”.`
            },
            {
              role: "user",
              content: transcribedText
            }
          ],
          response_format: { type: "json_object" }
        });
        
        const analysisResult = JSON.parse(analysisResponse.choices[0].message.content || '{"suggestions":[]}');
        smartSuggestions = analysisResult.suggestions || [];
        
        console.log("ğŸ¤– Smart suggestions analysis completed:", smartSuggestions.length, "suggestions");
        
      } catch (analysisError) {
        console.error("Smart suggestions analysis failed:", analysisError);
        // Continue without suggestions rather than failing the whole transcription
      }
    }
    
    return {
      success: true,
      transcription: transcribedText,
      duration: transcription.duration || 0,
      detectedLanguage,
      confidence: 0.9, // Whisper doesn't provide confidence scores, but it's generally reliable
      smartSuggestions
    };
  } catch (error: any) {
    console.error("Audio transcription error:", {
      message: error.message,
      status: error.status,
      code: error.code,
      type: error.type,
      error: error
    });
    
    return {
      success: false,
      error: `ìŒì„± ë³€í™˜ ì‹¤íŒ¨: ${error.message || 'Unknown error'}`
    };
  }
}

// íŒŒì¼ ìš”ì•½ ìƒì„± í•¨ìˆ˜
export async function generateFileSummary(fileName: string, fileType: string, fileContent?: string): Promise<string> {
  try {
    console.log(`Generating file summary for: ${fileName} (${fileType})`);
    
    let prompt = `ë‹¤ìŒ íŒŒì¼ì— ëŒ€í•œ ì•„ì£¼ ê°„ë‹¨í•œ ìš”ì•½ì„ í•œ ì¤„ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”. 15ì ì´ë‚´ë¡œ í•µì‹¬ ë‚´ìš©ë§Œ ì„¤ëª…í•˜ì„¸ìš”.
íŒŒì¼ëª…: ${fileName}
íŒŒì¼ ìœ í˜•: ${fileType}`;

    if (fileContent) {
      prompt += `\níŒŒì¼ ë‚´ìš©: ${fileContent.substring(0, 1000)}...`;
    }

    const response = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [
        {
          role: "system",
          content: "ë‹¹ì‹ ì€ íŒŒì¼ ë‚´ìš©ì„ ê°„ë‹¨íˆ ìš”ì•½í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 15ì ì´ë‚´ë¡œ í•µì‹¬ë§Œ ì„¤ëª…í•˜ì„¸ìš”."
        },
        {
          role: "user",
          content: prompt
        }
      ],
      max_tokens: 30,
      temperature: 0.3
    });

    const summary = response.choices[0].message.content?.trim() || "íŒŒì¼";
    console.log(`File summary generated: "${summary}"`);
    
    return summary;
  } catch (error: any) {
    console.error("File summary generation error:", error);
    
    // íŒŒì¼ í™•ì¥ìë¡œ ê¸°ë³¸ ì„¤ëª… ì œê³µ
    const extension = fileName.split('.').pop()?.toLowerCase();
    switch (extension) {
      case 'pdf': return 'PDF ë¬¸ì„œ';
      case 'doc':
      case 'docx': return 'Word ë¬¸ì„œ';
      case 'xls':
      case 'xlsx': return 'Excel íŒŒì¼';
      case 'ppt':
      case 'pptx': return 'PPT íŒŒì¼';
      case 'txt': return 'í…ìŠ¤íŠ¸ íŒŒì¼';
      case 'jpg':
      case 'jpeg':
      case 'png':
      case 'gif': return 'ì´ë¯¸ì§€';
      case 'mp4':
      case 'avi':
      case 'mov': return 'ë™ì˜ìƒ';
      case 'mp3':
      case 'wav': return 'ìŒì„± íŒŒì¼';
      case 'zip':
      case 'rar': return 'ì••ì¶• íŒŒì¼';
      default: return 'íŒŒì¼';
    }
  }
}

// Analyze message content and suggest personalized emoji reactions
export async function analyzeMessageForEmojiSuggestions(
  messageContent: string, 
  messageType: string = 'text',
  senderContext?: string
): Promise<{ success: boolean; suggestions: Array<{ emoji: string; name: string; confidence: number }> }> {
  try {
    // the newest OpenAI model is "gpt-4o" which was released May 13, 2024. do not change this unless explicitly requested by the user
    const response = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [
        {
          role: "system",
          content: `You are an expert emoji suggestion system. Analyze the given message content and suggest 3-5 most relevant emoji reactions that users might want to use to react to this message.

Consider:
- Message sentiment and emotion
- Content topic and context
- Cultural appropriateness (Korean/international context)
- Popular reaction patterns on messaging apps

Return your response in JSON format with this structure:
{
  "suggestions": [
    {
      "emoji": "ğŸ˜€",
      "name": "grinning_face",
      "confidence": 0.85
    }
  ]
}

Prioritize commonly used reaction emojis like: â¤ï¸, ğŸ˜‚, ğŸ˜¢, ğŸ˜®, ğŸ‘, ğŸ‘, ğŸ”¥, ğŸ’¯, ğŸ‰, ğŸ˜, ğŸ¤”, ğŸ˜¡, ğŸ˜­, ğŸ™, ğŸ‘, etc.`
        },
        {
          role: "user",
          content: `Analyze this ${messageType} message and suggest emoji reactions: "${messageContent}"`
        }
      ],
      response_format: { type: "json_object" },
      max_tokens: 300,
    });

    const result = JSON.parse(response.choices[0].message.content || '{"suggestions": []}');
    
    // Validate and filter suggestions
    const validSuggestions = (result.suggestions || [])
      .filter((s: any) => s.emoji && s.name && typeof s.confidence === 'number')
      .slice(0, 5); // Limit to 5 suggestions

    return {
      success: true,
      suggestions: validSuggestions
    };
    
  } catch (error) {
    console.error('Error analyzing message for emoji suggestions:', error);
    
    // Return default popular reactions as fallback
    return {
      success: false,
      suggestions: [
        { emoji: "â¤ï¸", name: "heart", confidence: 0.7 },
        { emoji: "ğŸ˜‚", name: "joy", confidence: 0.6 },
        { emoji: "ğŸ‘", name: "thumbs_up", confidence: 0.6 },
        { emoji: "ğŸ˜®", name: "open_mouth", confidence: 0.5 }
      ]
    };
  }
}