import OpenAI from "openai";
import fs from "fs";
import path from "path";

// the newest OpenAI model is "gpt-4o" which was released May 13, 2024. do not change this unless explicitly requested by the user
const openai = new OpenAI({ 
  apiKey: process.env.OPENAI_API_KEY,
  timeout: 30000 // 30 second timeout
});

// Test if API key is available
if (!process.env.OPENAI_API_KEY) {
  console.error("OPENAI_API_KEY environment variable is not set");
} else {
  console.log("OpenAI API key is configured");
}

export interface CommandResponse {
  success: boolean;
  content: string;
  type: 'text' | 'json';
}

// /translate command - translate text to specified language
export async function translateText(text: string, targetLanguage: string = 'English'): Promise<CommandResponse> {
  try {
    console.log(`Attempting translation: "${text}" to ${targetLanguage}`);
    
    const response = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [
        {
          role: "system",
          content: `You are a professional translator. Translate the following text to ${targetLanguage}. Only return the translated text, nothing else.`
        },
        {
          role: "user",
          content: text
        }
      ],
      max_tokens: 1000,
    });

    console.log("OpenAI response received successfully");
    return {
      success: true,
      content: response.choices[0].message.content || "Translation failed",
      type: 'text'
    };
  } catch (error: any) {
    console.error("Translation error details:", {
      message: error.message,
      status: error.status,
      code: error.code,
      type: error.type,
      error: error
    });
    
    return {
      success: false,
      content: `Translation failed: ${error.message || 'Unknown error'}`,
      type: 'text'
    };
  }
}

// /calculate command - perform mathematical calculations using JavaScript eval
export async function calculateExpression(expression: string): Promise<CommandResponse> {
  try {
    // ë³´ì•ˆì„ ìœ„í•´ í—ˆìš©ëœ ë¬¸ìë§Œ í•„í„°ë§
    const sanitizedExpression = expression.replace(/[^0-9+\-*/.() ]/g, '');
    
    if (sanitizedExpression !== expression) {
      return {
        success: false,
        content: "Invalid characters in expression. Only numbers, +, -, *, /, (, ), and spaces are allowed.",
        type: 'text'
      };
    }

    // ë¹ˆ í‘œí˜„ì‹ ì²´í¬
    if (!sanitizedExpression.trim()) {
      return {
        success: false,
        content: "Please provide a mathematical expression to calculate.",
        type: 'text'
      };
    }

    // JavaScriptì˜ evalì„ ì‚¬ìš©í•˜ì—¬ ê³„ì‚° (ë³´ì•ˆìƒ sanitizedëœ ì…ë ¥ë§Œ ì‚¬ìš©)
    const result = eval(sanitizedExpression);
    
    // ê²°ê³¼ê°€ ìœ íš¨í•œ ìˆ«ìì¸ì§€ í™•ì¸
    if (typeof result !== 'number' || isNaN(result)) {
      return {
        success: false,
        content: "Invalid mathematical expression.",
        type: 'text'
      };
    }

    // ìˆ«ì í¬ë§·íŒ… (í° ìˆ«ìëŠ” ì½¤ë§ˆ ì¶”ê°€)
    const formattedResult = result.toLocaleString();

    return {
      success: true,
      content: formattedResult,
      type: 'text'
    };
  } catch (error) {
    return {
      success: false,
      content: "Error calculating expression. Please check your syntax.",
      type: 'text'
    };
  }
}

// /summarize command - summarize text
export async function summarizeText(text: string): Promise<CommandResponse> {
  try {
    const response = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [
        {
          role: "system",
          content: "You are a text summarizer. Provide a concise summary of the following text. Keep it brief and capture the main points."
        },
        {
          role: "user",
          content: text
        }
      ],
      max_tokens: 300,
    });

    return {
      success: true,
      content: response.choices[0].message.content || "Summarization failed",
      type: 'text'
    };
  } catch (error) {
    return {
      success: false,
      content: "Summarization service unavailable",
      type: 'text'
    };
  }
}

// /vibe command - analyze sentiment/vibe of text
export async function analyzeVibe(text: string): Promise<CommandResponse> {
  try {
    const response = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [
        {
          role: "system",
          content: "You are a sentiment analyzer. Analyze the vibe/sentiment of the text and provide a rating from 1-5 stars and describe the emotional tone. Respond with JSON in this format: { 'rating': number, 'emotion': string, 'description': string }"
        },
        {
          role: "user",
          content: text
        }
      ],
      response_format: { type: "json_object" },
      max_tokens: 200,
    });

    const result = JSON.parse(response.choices[0].message.content || '{}');
    const stars = 'â­'.repeat(Math.max(1, Math.min(5, result.rating || 3)));
    
    return {
      success: true,
      content: `${stars} ${result.emotion || 'Neutral'}\n${result.description || 'Unable to analyze sentiment'}`,
      type: 'text'
    };
  } catch (error) {
    return {
      success: false,
      content: "Vibe analysis service unavailable",
      type: 'text'
    };
  }
}

// /poll command - create a poll
export async function createPoll(question: string, options: string[]): Promise<CommandResponse> {
  try {
    if (options.length < 2) {
      return {
        success: false,
        content: "Poll needs at least 2 options. Format: /poll Question? Option1,Option2,Option3",
        type: 'text'
      };
    }

    const pollData = {
      question: question.trim(),
      options: options.map((opt, index) => ({
        id: index + 1,
        text: opt.trim(),
        votes: 0
      })),
      totalVotes: 0,
      createdAt: new Date().toISOString()
    };

    return {
      success: true,
      content: JSON.stringify(pollData),
      type: 'json'
    };
  } catch (error) {
    return {
      success: false,
      content: "Failed to create poll",
      type: 'text'
    };
  }
}

// Command parser to handle different command types
export async function processCommand(commandText: string): Promise<CommandResponse> {
  const parts = commandText.trim().split(' ');
  const command = parts[0].toLowerCase();
  const args = parts.slice(1).join(' ');

  switch (command) {
    case '/translate':
      const translateParts = args.split(' to ');
      if (translateParts.length === 2) {
        return translateText(translateParts[0], translateParts[1]);
      }
      return translateText(args);

    case '/calculate':
    case '/calc':
      return calculateExpression(args);

    case '/summarize':
      return summarizeText(args);

    case '/vibe':
      return analyzeVibe(args);

    case '/poll':
      const pollParts = args.split('?');
      if (pollParts.length !== 2) {
        return {
          success: false,
          content: "Poll format: /poll Question? Option1,Option2,Option3",
          type: 'text'
        };
      }
      const question = pollParts[0] + '?';
      const options = pollParts[1].split(',').map(opt => opt.trim()).filter(opt => opt.length > 0);
      return createPoll(question, options);

    default:
      return {
        success: false,
        content: `Unknown command: ${command}\n\nAvailable commands:\n/translate [text] (to [language])\n/calculate [expression]\n/summarize [text]\n/vibe [text]\n/poll [question]? [option1,option2,option3]`,
        type: 'text'
      };
  }
}

// Audio transcription for voice messages
export async function transcribeAudio(filePath: string): Promise<{ 
  success: boolean, 
  transcription?: string, 
  duration?: number, 
  detectedLanguage?: string,
  confidence?: number,
  error?: string 
}> {
  try {
    console.log("Starting audio transcription with language detection...");
    console.log("Audio file path:", filePath);
    
    // Read file as buffer and detect proper audio format
    const audioBuffer = fs.readFileSync(filePath);
    console.log("Audio buffer read successfully, size:", audioBuffer.length, "bytes");
    
    // iPhone PWA enhanced audio format detection
    let mimeType = "audio/webm";
    let fileName = "audio.webm";
    
    // Check file extension for proper format detection
    const fileExtension = path.extname(filePath).toLowerCase();
    
    // iPhone PWA audio format priority handling
    if (fileExtension === '.mp4' || fileExtension === '.m4a') {
      mimeType = "audio/mp4";
      fileName = "audio.mp4";
      console.log("ğŸ¤ iPhone PWA audio format detected: MP4");
    } else if (fileExtension === '.wav') {
      mimeType = "audio/wav";
      fileName = "audio.wav";
      console.log("ğŸ¤ WAV audio format detected");
    } else if (fileExtension === '.ogg') {
      mimeType = "audio/ogg";
      fileName = "audio.ogg";
      console.log("ğŸ¤ OGG audio format detected");
    } else {
      // For iPhone PWA, prefer MP4 as fallback
      console.log("ğŸ¤ Unknown format, using iPhone PWA compatible MP4 fallback");
      mimeType = "audio/mp4";
      fileName = "audio.mp4";
    }
    
    // Additional validation for iPhone PWA audio
    if (audioBuffer.length < 1024) {
      console.log("âš ï¸ Audio buffer very small, likely silent recording");
      return {
        success: false,
        transcription: "",
        detectedLanguage: "ko",
        duration: 0,
        confidence: 0,
        error: "SILENT_RECORDING"
      };
    }
    
    console.log(`Using audio format: ${mimeType} for file: ${fileName} (${audioBuffer.length} bytes)`);
    
    // Create a Blob with proper MIME type
    const audioBlob = new Blob([audioBuffer], { type: mimeType });
    
    // Create FormData for OpenAI API with proper filename and format
    const formData = new FormData();
    formData.append("file", audioBlob, fileName);
    formData.append("model", "whisper-1");
    formData.append("response_format", "verbose_json");
    formData.append("language", "ko"); // Set default language to Korean for better iPhone PWA performance
    
    console.log("FormData prepared for OpenAI API");
    
    // Make direct fetch request to OpenAI API
    const response = await fetch("https://api.openai.com/v1/audio/transcriptions", {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${process.env.OPENAI_API_KEY}`,
      },
      body: formData
    });
    
    if (!response.ok) {
      const errorText = await response.text();
      console.error("OpenAI API Error:", response.status, errorText);
      
      // Handle audio too short error as silent recording
      if (errorText.includes("Audio file is too short") || errorText.includes("audio_too_short")) {
        console.log("ğŸ”‡ Audio file too short, treating as silent recording");
        return {
          success: false,
          transcription: "",
          detectedLanguage: "ko",
          duration: 0,
          confidence: 0,
          error: "SILENT_RECORDING"
        };
      }
      
      throw new Error(`OpenAI API Error: ${response.status} ${errorText}`);
    }
    
    const transcription = await response.json();
    console.log("Direct API call successful");

    console.log("Audio transcription completed:", {
      text: transcription.text,
      language: transcription.language,
      duration: transcription.duration
    });
    
    // Map language codes to readable names
    const languageNames: { [key: string]: string } = {
      'ko': 'í•œêµ­ì–´',
      'en': 'English', 
      'hu': 'Magyar',
      'de': 'Deutsch',
      'ja': 'æ—¥æœ¬èª',
      'zh': 'ä¸­æ–‡',
      'es': 'EspaÃ±ol',
      'fr': 'FranÃ§ais',
      'it': 'Italiano',
      'pt': 'PortuguÃªs',
      'ru': 'Ğ ÑƒÑÑĞºĞ¸Ğ¹'
    };
    
    const detectedLanguage = languageNames[transcription.language] || transcription.language;
    const transcribedText = transcription.text || "";
    
    // Check if transcription contains meaningful content
    const isEmptyOrNoise = (text: string): boolean => {
      if (!text || text.trim().length === 0) return true;
      
      // Enhanced iPhone PWA noise patterns - comprehensive hallucination detection
      const noisePatterns = [
        /^[\s.,!?]*$/,  // Only punctuation and whitespace
        /^(um|uh|ah|eh|hmm|mm|ì•„|ì–´|ìŒ|ìœ¼|ì•„ìš°|ì–´ìš°|ìŒ\.\.\.|\.\.\.)+[\s.,!?]*$/i,  // Filler sounds
        /^[\uD83C-\uDBFF\uDC00-\uDFFF]+[\s.,!?]*$/,  // Only emojis
        /^[ğŸ“¢ğŸµğŸ¤ğŸ”ŠğŸ”‡ğŸ“»]+[\s.,!?]*$/,  // Audio/sound emojis
        /thank you|ê°ì‚¬í•©ë‹ˆë‹¤|ê³ ë§ˆì›Œ|sorry|ì£„ì†¡|ë¯¸ì•ˆ/i,  // Common polite expressions that might be background audio
        // Enhanced news anchor patterns (iPhone PWA Whisper hallucination)
        /MBC.*ë‰´ìŠ¤.*ì…ë‹ˆë‹¤|KBS.*ë‰´ìŠ¤|SBS.*ë‰´ìŠ¤|ë‰´ìŠ¤ë°ìŠ¤í¬|ë‰´ìŠ¤ë£¸/i,
        /ì´ë•ì˜ì…ë‹ˆë‹¤|ì´ë•ì˜.*ë‰´ìŠ¤|ë‰´ìŠ¤.*ì´ë•ì˜/i,  // Specific iPhone PWA hallucination pattern
        /ì•µì»¤.*ì…ë‹ˆë‹¤|ê¸°ì.*ì…ë‹ˆë‹¤|ì•„ë‚˜ìš´ì„œ.*ì…ë‹ˆë‹¤|ìºìŠ¤í„°.*ì…ë‹ˆë‹¤/i,  // News presenter patterns
        /ì˜¤ëŠ˜.*ë‰´ìŠ¤|ì§€ê¸ˆ.*ë‰´ìŠ¤|ë‹¤ìŒ.*ë‰´ìŠ¤|ì´ì–´ì„œ.*ë‰´ìŠ¤/i,  // News timing patterns
        /ì•ˆë…•í•˜ì„¸ìš”.*ì…ë‹ˆë‹¤|ì—¬ëŸ¬ë¶„.*ì…ë‹ˆë‹¤|ì‹œì²­í•´.*ì£¼ì…”ì„œ/i,  // Generic formal greeting patterns
        /ë°©ì†¡.*ì‹œì‘|í”„ë¡œê·¸ë¨.*ì‹œì‘|ë‰´ìŠ¤.*ì‹œì‘|ë°©ì†¡.*ë“œë¦¬ê² ìŠµë‹ˆë‹¤/i,  // Broadcasting start patterns
        /^(ë„¤|ì˜ˆ|ì•„|ì–´|ìŒ|ê·¸|ì €|ë­|ì ê¹|ì ì‹œ|ì–´ì„œ|ì´ì œ|ê·¸ëŸ¼|ê·¸ë˜ì„œ)[\s.,!?]*$/i,  // Single Korean filler words
        // iPhone PWA specific detection patterns
        /^(í…ŒìŠ¤íŠ¸|test|ì‹œì‘|start|ìŒì„±|voice|ë…¹ìŒ|record|hello|hi)[\s.,!?]*$/i,  // Test/start words
        /ì ê¹ë§Œìš”|ì£„ì†¡í•©ë‹ˆë‹¤|ì‹¤ë¡€í•©ë‹ˆë‹¤|ì‹¤ë¡€í•˜ê² ìŠµë‹ˆë‹¤/i,  // Polite interruptions
        /^.{1,4}[\s.,!?]*$/i,  // Very short meaningless utterances (1-4 characters)
        /ë°˜ê°‘ìŠµë‹ˆë‹¤|ë§Œë‚˜ì„œ.*ë°˜ê°‘ìŠµë‹ˆë‹¤|ì²˜ìŒ.*ëµ™ê² ìŠµë‹ˆë‹¤/i  // Generic greetings
      ];
      
      // Check text length (very short transcriptions are likely noise)
      if (text.trim().length < 5) return true;
      
      // Check against noise patterns
      return noisePatterns.some(pattern => pattern.test(text.trim()));
    };
    
    // If transcription is empty or just noise, return cancellation response
    if (isEmptyOrNoise(transcribedText)) {
      console.log("ğŸ”‡ Voice recording contains no meaningful speech, canceling message");
      return {
        success: false,
        transcription: "",
        error: "SILENT_RECORDING", // Special error code for silent recordings
        duration: transcription.duration || 0,
        detectedLanguage,
        confidence: 0
      };
    }
    
    return {
      success: true,
      transcription: transcribedText,
      duration: transcription.duration || 0,
      detectedLanguage,
      confidence: 0.9 // Whisper doesn't provide confidence scores, but it's generally reliable
    };
  } catch (error: any) {
    console.error("Audio transcription error:", {
      message: error.message,
      status: error.status,
      code: error.code,
      type: error.type,
      error: error
    });
    
    return {
      success: false,
      error: `ìŒì„± ë³€í™˜ ì‹¤íŒ¨: ${error.message || 'Unknown error'}`
    };
  }
}

// íŒŒì¼ ìš”ì•½ ìƒì„± í•¨ìˆ˜
export async function generateFileSummary(fileName: string, fileType: string, fileContent?: string): Promise<string> {
  try {
    console.log(`Generating file summary for: ${fileName} (${fileType})`);
    
    let prompt = `ë‹¤ìŒ íŒŒì¼ì— ëŒ€í•œ ì•„ì£¼ ê°„ë‹¨í•œ ìš”ì•½ì„ í•œ ì¤„ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”. 15ì ì´ë‚´ë¡œ í•µì‹¬ ë‚´ìš©ë§Œ ì„¤ëª…í•˜ì„¸ìš”.
íŒŒì¼ëª…: ${fileName}
íŒŒì¼ ìœ í˜•: ${fileType}`;

    if (fileContent) {
      prompt += `\níŒŒì¼ ë‚´ìš©: ${fileContent.substring(0, 1000)}...`;
    }

    const response = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [
        {
          role: "system",
          content: "ë‹¹ì‹ ì€ íŒŒì¼ ë‚´ìš©ì„ ê°„ë‹¨íˆ ìš”ì•½í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 15ì ì´ë‚´ë¡œ í•µì‹¬ë§Œ ì„¤ëª…í•˜ì„¸ìš”."
        },
        {
          role: "user",
          content: prompt
        }
      ],
      max_tokens: 30,
      temperature: 0.3
    });

    const summary = response.choices[0].message.content?.trim() || "íŒŒì¼";
    console.log(`File summary generated: "${summary}"`);
    
    return summary;
  } catch (error: any) {
    console.error("File summary generation error:", error);
    
    // íŒŒì¼ í™•ì¥ìë¡œ ê¸°ë³¸ ì„¤ëª… ì œê³µ
    const extension = fileName.split('.').pop()?.toLowerCase();
    switch (extension) {
      case 'pdf': return 'PDF ë¬¸ì„œ';
      case 'doc':
      case 'docx': return 'Word ë¬¸ì„œ';
      case 'xls':
      case 'xlsx': return 'Excel íŒŒì¼';
      case 'ppt':
      case 'pptx': return 'PPT íŒŒì¼';
      case 'txt': return 'í…ìŠ¤íŠ¸ íŒŒì¼';
      case 'jpg':
      case 'jpeg':
      case 'png':
      case 'gif': return 'ì´ë¯¸ì§€';
      case 'mp4':
      case 'avi':
      case 'mov': return 'ë™ì˜ìƒ';
      case 'mp3':
      case 'wav': return 'ìŒì„± íŒŒì¼';
      case 'zip':
      case 'rar': return 'ì••ì¶• íŒŒì¼';
      default: return 'íŒŒì¼';
    }
  }
}

// AI Chat Assistant - Answer questions based on chat room context
export async function answerChatQuestion(
  question: string,
  chatMessages: Array<{ senderName: string; content: string; createdAt: string; messageType?: string }>
): Promise<CommandResponse> {
  try {
    console.log(`AI Chat Assistant: Answering question with ${chatMessages.length} messages as context`);
    
    // Prepare chat context from messages
    const chatContext = chatMessages
      .slice(-100) // Use last 100 messages for context
      .map(msg => {
        const date = new Date(msg.createdAt).toLocaleString('ko-KR');
        const content = msg.messageType === 'file' ? '[íŒŒì¼]' : 
                       msg.messageType === 'voice' ? '[ìŒì„± ë©”ì‹œì§€]' : 
                       msg.messageType === 'image' ? '[ì´ë¯¸ì§€]' : 
                       msg.content;
        return `[${date}] ${msg.senderName}: ${content}`;
      })
      .join('\n');
    
    if (!chatContext.trim()) {
      return {
        success: false,
        content: "ì•„ì§ ëŒ€í™” ë‚´ìš©ì´ ì—†ì–´ì„œ ë‹µë³€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì±„íŒ…ì„ ì‹œì‘í•œ í›„ ë‹¤ì‹œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”.",
        type: 'text'
      };
    }

    const response = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [
        {
          role: "system",
          content: `ë‹¹ì‹ ì€ Dovie Messengerì˜ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì±„íŒ…ë°©ì˜ ëŒ€í™” ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.

ë‹µë³€ ê°€ì´ë“œë¼ì¸:
1. ì±„íŒ… ê¸°ë¡ì— ëª…í™•í•œ ì •ë³´ê°€ ìˆìœ¼ë©´ ì •í™•íˆ ì¸ìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”
2. ë‚ ì§œ, ì‹œê°„, ì´ë¦„ ë“± êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ í¬í•¨í•˜ì„¸ìš”
3. ì •ë³´ê°€ ë¶ˆí™•ì‹¤í•˜ê±°ë‚˜ ì—†ìœ¼ë©´ ì†”ì§íˆ ë§í•˜ì„¸ìš”
4. ì¹œê·¼í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ëŒ€í™”í•˜ì„¸ìš”
5. ë‹µë³€ì€ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš” (3-4 ë¬¸ì¥ ì´ë‚´)

ì˜ˆì‹œ:
ì§ˆë¬¸: "ìˆ˜ì§„ì´ ìƒì¼ì´ ì–¸ì œì•¼?"
ë‹µë³€: "ì±„íŒ… ê¸°ë¡ì„ ë³´ë‹ˆ 1ì›” 15ì¼ì— ìˆ˜ì§„ë‹˜ì´ 'ë‚´ì¼ì´ ë‚´ ìƒì¼ì´ì•¼'ë¼ê³  í•˜ì…¨ì–´ìš”. ê·¸ëŸ¬ë‹ˆê¹Œ ìˆ˜ì§„ë‹˜ ìƒì¼ì€ 1ì›” 16ì¼ì…ë‹ˆë‹¤!"

ì§ˆë¬¸: "ë‚´ì¼ ë­í•œë‹¤ê³  í–ˆì§€?"
ë‹µë³€: "ì–´ì œ ëŒ€í™”ì—ì„œ 'ë‚´ì¼ ì €ë… 7ì‹œì— ê°•ë‚¨ì—­ì—ì„œ ë§Œë‚˜ì'ê³  ì•½ì†í•˜ì…¨ë„¤ìš”. ìŠì§€ ë§ˆì„¸ìš”!"

ì§ˆë¬¸: "ì§€ë‚œì£¼ì— ë¬´ìŠ¨ ì˜í™” ë´¤ì–´?"
ë‹µë³€: "ì£„ì†¡í•˜ì§€ë§Œ ì±„íŒ… ê¸°ë¡ì— ì˜í™”ì— ëŒ€í•œ ëŒ€í™”ê°€ ì—†ì–´ì„œ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."`
        },
        {
          role: "user",
          content: `ì±„íŒ… ê¸°ë¡:\n${chatContext}\n\nì§ˆë¬¸: ${question}`
        }
      ],
      max_tokens: 500,
      temperature: 0.7
    });

    const answer = response.choices[0].message.content?.trim();
    
    if (!answer) {
      return {
        success: false,
        content: "ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
        type: 'text'
      };
    }

    console.log("AI Chat Assistant: Answer generated successfully");
    
    return {
      success: true,
      content: answer,
      type: 'text'
    };
  } catch (error: any) {
    console.error("AI Chat Assistant error:", {
      message: error.message,
      status: error.status,
      code: error.code
    });
    
    return {
      success: false,
      content: `AI ë‹µë³€ ì‹¤íŒ¨: ${error.message || 'Unknown error'}. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.`,
      type: 'text'
    };
  }
}

// Analyze message content and suggest personalized emoji reactions
export async function analyzeMessageForEmojiSuggestions(
  messageContent: string, 
  messageType: string = 'text',
  senderContext?: string
): Promise<{ success: boolean; suggestions: Array<{ emoji: string; name: string; confidence: number }> }> {
  try {
    // the newest OpenAI model is "gpt-4o" which was released May 13, 2024. do not change this unless explicitly requested by the user
    const response = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [
        {
          role: "system",
          content: `You are an expert emoji suggestion system. Analyze the given message content and suggest 3-5 most relevant emoji reactions that users might want to use to react to this message.

Consider:
- Message sentiment and emotion
- Content topic and context
- Cultural appropriateness (Korean/international context)
- Popular reaction patterns on messaging apps

Return your response in JSON format with this structure:
{
  "suggestions": [
    {
      "emoji": "ğŸ˜€",
      "name": "grinning_face",
      "confidence": 0.85
    }
  ]
}

Prioritize commonly used reaction emojis like: â¤ï¸, ğŸ˜‚, ğŸ˜¢, ğŸ˜®, ğŸ‘, ğŸ‘, ğŸ”¥, ğŸ’¯, ğŸ‰, ğŸ˜, ğŸ¤”, ğŸ˜¡, ğŸ˜­, ğŸ™, ğŸ‘, etc.`
        },
        {
          role: "user",
          content: `Analyze this ${messageType} message and suggest emoji reactions: "${messageContent}"`
        }
      ],
      response_format: { type: "json_object" },
      max_tokens: 300,
    });

    const result = JSON.parse(response.choices[0].message.content || '{"suggestions": []}');
    
    // Validate and filter suggestions
    const validSuggestions = (result.suggestions || [])
      .filter((s: any) => s.emoji && s.name && typeof s.confidence === 'number')
      .slice(0, 5); // Limit to 5 suggestions

    return {
      success: true,
      suggestions: validSuggestions
    };
    
  } catch (error) {
    console.error('Error analyzing message for emoji suggestions:', error);
    
    // Return default popular reactions as fallback
    return {
      success: false,
      suggestions: [
        { emoji: "â¤ï¸", name: "heart", confidence: 0.7 },
        { emoji: "ğŸ˜‚", name: "joy", confidence: 0.6 },
        { emoji: "ğŸ‘", name: "thumbs_up", confidence: 0.6 },
        { emoji: "ğŸ˜®", name: "open_mouth", confidence: 0.5 }
      ]
    };
  }
}

// Analyze message for important notices (appointments, schedules, deadlines, important info)
export async function analyzeMessageForNotices(
  messageContent: string,
  senderName: string,
  chatRoomName: string
): Promise<{
  success: boolean;
  hasNotice: boolean;
  notices: Array<{
    type: 'appointment' | 'schedule' | 'reminder' | 'important_info' | 'deadline';
    content: string;
    metadata?: {
      date?: string;
      time?: string;
      location?: string;
      participants?: string[];
      priority?: 'low' | 'medium' | 'high';
    };
  }>;
}> {
  try {
    console.log(`Analyzing message for notices: "${messageContent}"`);

    const response = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [
        {
          role: "system",
          content: `ë‹¹ì‹ ì€ ì±„íŒ… ë©”ì‹œì§€ë¥¼ ë¶„ì„í•˜ì—¬ ì¤‘ìš”í•œ ì•Œë¦¼ì„ ê°ì§€í•˜ëŠ” AIì…ë‹ˆë‹¤.

ë‹¤ìŒê³¼ ê°™ì€ ì •ë³´ë¥¼ ê°ì§€í•˜ê³  JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”:

1. **appointment** (ì•½ì†): íŠ¹ì • ì‹œê°„ê³¼ ì¥ì†Œì—ì„œ ë§Œë‚˜ëŠ” ì•½ì†
   ì˜ˆ: "ë‚´ì¼ 3ì‹œì— ê°•ë‚¨ì—­ì—ì„œ ë³´ì", "ë‹¤ìŒì£¼ ì›”ìš”ì¼ ì €ë… 7ì‹œ íšŒì˜"

2. **schedule** (ì¼ì •): íŠ¹ì • ë‚ ì§œì— í•´ì•¼ í•  ì¼ì´ë‚˜ í–‰ì‚¬
   ì˜ˆ: "ì´ë²ˆ ì£¼ë§ì— ì—¬í–‰ ê°€ì", "ë‹¤ìŒë‹¬ 15ì¼ì´ ë°œí‘œë‚ "

3. **deadline** (ë§ˆê°): íŠ¹ì • ë‚ ì§œê¹Œì§€ ì™„ë£Œí•´ì•¼ í•˜ëŠ” ì¼
   ì˜ˆ: "ê¸ˆìš”ì¼ê¹Œì§€ ë³´ê³ ì„œ ì œì¶œ", "ë‚´ì¼ê¹Œì§€ ê²°ì œí•´ì•¼ í•´"

4. **reminder** (ë¦¬ë§ˆì¸ë”): ìŠì§€ ë§ì•„ì•¼ í•  ì¤‘ìš”í•œ ì‚¬í•­
   ì˜ˆ: "ì—„ë§ˆ ìƒì¼ ìŠì§€ë§ˆ", "ë‚´ì¼ íƒë°° ë°›ì•„ì•¼ í•´"

5. **important_info** (ì¤‘ìš” ì •ë³´): ê¸°ì–µí•´ì•¼ í•  ì¤‘ìš”í•œ ì •ë³´
   ì˜ˆ: "ë¹„ë°€ë²ˆí˜¸ëŠ” 1234ì•¼", "íšŒì˜ì‹¤ì€ 3ì¸µì´ì•¼"

ë¶„ì„ ê·œì¹™:
- ì¼ìƒì ì¸ ëŒ€í™”ëŠ” ë¬´ì‹œ (ì˜ˆ: "ì•ˆë…•", "ë­í•´?", "ã…‹ã…‹ã…‹")
- ëª…í™•í•œ ë‚ ì§œ/ì‹œê°„ì´ ìˆëŠ” ê²½ìš° metadataì— í¬í•¨
- ì¥ì†Œ ì •ë³´ê°€ ìˆìœ¼ë©´ locationì— í¬í•¨
- ì°¸ì„ì ì •ë³´ê°€ ìˆìœ¼ë©´ participantsì— í¬í•¨
- ê¸´ê¸‰ë„ì— ë”°ë¼ priority ì„¤ì • (high/medium/low)

ì‘ë‹µ í˜•ì‹:
{
  "hasNotice": true/false,
  "notices": [
    {
      "type": "appointment",
      "content": "ê°„ê²°í•œ ì•Œë¦¼ ë‚´ìš© (í•œ ë¬¸ì¥)",
      "metadata": {
        "date": "2024-01-15",
        "time": "15:00",
        "location": "ê°•ë‚¨ì—­",
        "participants": ["ìˆ˜ì§„", "ë¯¼ìˆ˜"],
        "priority": "high"
      }
    }
  ]
}`
        },
        {
          role: "user",
          content: `ì±„íŒ…ë°©: ${chatRoomName}
ë³´ë‚¸ ì‚¬ëŒ: ${senderName}
ë©”ì‹œì§€: "${messageContent}"

ì´ ë©”ì‹œì§€ì—ì„œ ì¤‘ìš”í•œ ì•Œë¦¼ì„ ì¶”ì¶œí•˜ì„¸ìš”.`
        }
      ],
      response_format: { type: "json_object" },
      max_tokens: 500,
      temperature: 0.3
    });

    const result = JSON.parse(response.choices[0].message.content || '{"hasNotice": false, "notices": []}');

    console.log(`AI Notice Analysis Result:`, result);

    return {
      success: true,
      hasNotice: result.hasNotice || false,
      notices: result.notices || []
    };

  } catch (error: any) {
    console.error("AI Notice Analysis error:", {
      message: error.message,
      status: error.status,
      code: error.code
    });

    return {
      success: false,
      hasNotice: false,
      notices: []
    };
  }
}

// AI Voice Enhancement - Correct transcription using chat context
export async function correctTranscriptionWithContext(
  transcription: string,
  chatMessages: Array<{ senderName: string; content: string; createdAt: string; messageType?: string }>,
  senderName: string
): Promise<{ success: boolean; correctedText?: string; error?: string }> {
  try {
    console.log(`AI Voice Enhancement: Correcting transcription with ${chatMessages.length} messages as context`);
    
    // Extract user's speaking style from their previous messages
    const userMessages = chatMessages
      .filter(msg => msg.senderName === senderName && msg.messageType === 'text')
      .slice(-20) // Last 20 text messages from the user (reduced from 50)
      .map(msg => msg.content);
    
    // Prepare recent chat context for understanding topic (with character limit)
    const MAX_CONTEXT_CHARS = 2000;
    let recentContextMessages = chatMessages
      .slice(-20) // Last 20 messages for context (reduced from 30)
      .map(msg => {
        const content = msg.messageType === 'file' ? '[íŒŒì¼]' : 
                       msg.messageType === 'voice' ? '[ìŒì„± ë©”ì‹œì§€]' : 
                       msg.messageType === 'image' ? '[ì´ë¯¸ì§€]' : 
                       msg.content;
        return `${msg.senderName}: ${content}`;
      });
    
    // Truncate context if too long to avoid token limits
    let recentContext = recentContextMessages.join('\n');
    if (recentContext.length > MAX_CONTEXT_CHARS) {
      // Take only the most recent messages that fit within the limit
      recentContext = recentContextMessages
        .reverse()
        .reduce((acc, msg) => {
          if ((acc + msg).length < MAX_CONTEXT_CHARS) {
            return msg + '\n' + acc;
          }
          return acc;
        }, '')
        .trim();
    }
    
    // Limit user style context
    const MAX_STYLE_CHARS = 1000;
    let userStyleContext = '';
    if (userMessages.length > 0) {
      const styleMessages = userMessages.slice(-5).join('\n'); // Reduced from 10
      userStyleContext = `\n\nì‚¬ìš©ìì˜ í‰ì†Œ ë§íˆ¬ ì˜ˆì‹œ:\n${
        styleMessages.length > MAX_STYLE_CHARS 
          ? styleMessages.substring(0, MAX_STYLE_CHARS) + '...' 
          : styleMessages
      }`;
    }

    const response = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [
        {
          role: "system",
          content: `ë‹¹ì‹ ì€ ìŒì„± ì¸ì‹ í…ìŠ¤íŠ¸ë¥¼ ë³´ì •í•˜ëŠ” AIì…ë‹ˆë‹¤. ì±„íŒ… íˆìŠ¤í† ë¦¬ì™€ ì‚¬ìš©ìì˜ ë§íˆ¬ë¥¼ ë¶„ì„í•˜ì—¬ Whisperê°€ ìƒì„±í•œ ì „ì‚¬ í…ìŠ¤íŠ¸ì˜ ì˜¤ë¥˜ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”.

ë³´ì • ê°€ì´ë“œë¼ì¸:
1. **ë§¥ë½ ê¸°ë°˜ ìˆ˜ì •**: ìµœê·¼ ëŒ€í™” ì£¼ì œì™€ ë§¥ë½ì„ ê³ ë ¤í•˜ì—¬ ë‹¨ì–´ë¥¼ ìˆ˜ì •
   - ì˜ˆ: "ê°•ë‚¨ì—­" â†’ "ê°•ë‚¨ì—­" (ì§€ëª… ë³´ì •)
   - ì˜ˆ: "ìˆ˜ì§„" â†’ "ìˆ˜ì§„" (ì´ë¦„ ë³´ì •)

2. **ì‚¬ìš©ì ë§íˆ¬ ìœ ì§€**: ì‚¬ìš©ìì˜ í‰ì†Œ ë§íˆ¬ì™€ ë¬¸ì²´ë¥¼ ë¶„ì„í•˜ê³  ê·¸ëŒ€ë¡œ ìœ ì§€
   - ì˜ˆ: í‰ì†Œ "~ì•¼"ë¥¼ ì“°ë©´ ê·¸ëŒ€ë¡œ ìœ ì§€
   - ì˜ˆ: ì´ëª¨í‹°ì½˜ì„ ìì£¼ ì“°ë©´ ì ì ˆíˆ ì¶”ê°€

3. **ë„ì–´ì“°ê¸° ë° ë§ì¶¤ë²•**: ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ìˆ˜ì •
   - ì˜ˆ: "ì•ˆë…•í•˜ì„¸ìš”ë§Œë‚˜ì„œë°˜ê°€ì›Œìš”" â†’ "ì•ˆë…•í•˜ì„¸ìš” ë§Œë‚˜ì„œ ë°˜ê°€ì›Œìš”"

4. **ë™ìŒì´ì˜ì–´ êµ¬ë¶„**: ë§¥ë½ì„ ê³ ë ¤í•˜ì—¬ ì˜¬ë°”ë¥¸ ë‹¨ì–´ ì„ íƒ
   - ì˜ˆ: "ë°¤" (ì‹œê°„) vs "ë°¤" (ì‹í’ˆ)
   - ì˜ˆ: "ë°°" (ì‹ ì²´) vs "ë°°" (ê³¼ì¼) vs "ë°°" (ë°°ì†¡)

5. **ìµœì†Œí•œì˜ ìˆ˜ì •**: ëª…ë°±í•œ ì˜¤ë¥˜ë§Œ ìˆ˜ì •í•˜ê³ , ë¶ˆí•„ìš”í•œ ë³€ê²½ì€ í•˜ì§€ ë§ˆì„¸ìš”
   - ì „ì‚¬ í…ìŠ¤íŠ¸ê°€ ì´ë¯¸ ì •í™•í•˜ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜

6. **ìì—°ìŠ¤ëŸ¬ìš´ êµ¬ì–´ì²´**: ìŒì„± ë©”ì‹œì§€ëŠ” êµ¬ì–´ì²´ì´ë¯€ë¡œ ë„ˆë¬´ ê²©ì‹ì²´ë¡œ ë°”ê¾¸ì§€ ë§ˆì„¸ìš”
   - ì˜ˆ: "í–ˆì–´" â†’ "í–ˆì–´" (O), "í–ˆìŠµë‹ˆë‹¤" (X)

ìˆ˜ì •ëœ í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜í•˜ì„¸ìš”. ì„¤ëª…ì´ë‚˜ ë¶€ê°€ ì •ë³´ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.`
        },
        {
          role: "user",
          content: `ìµœê·¼ ëŒ€í™” ë§¥ë½:\n${recentContext}${userStyleContext}\n\nìŒì„± ì¸ì‹ í…ìŠ¤íŠ¸:\n"${transcription}"\n\nìœ„ í…ìŠ¤íŠ¸ë¥¼ ë§¥ë½ê³¼ ì‚¬ìš©ì ë§íˆ¬ë¥¼ ê³ ë ¤í•˜ì—¬ ë³´ì •í•˜ì„¸ìš”.`
        }
      ],
      max_tokens: 300,
      temperature: 0.3
    });

    const correctedText = response.choices[0].message.content?.trim();
    
    if (!correctedText) {
      return {
        success: false,
        error: "í…ìŠ¤íŠ¸ ë³´ì • ì‹¤íŒ¨"
      };
    }

    console.log(`AI Voice Enhancement: Corrected "${transcription}" â†’ "${correctedText}"`);
    
    return {
      success: true,
      correctedText
    };
  } catch (error: any) {
    console.error("AI Voice Enhancement error:", {
      message: error.message,
      status: error.status,
      code: error.code
    });
    
    return {
      success: false,
      error: `AI ìŒì„± ë³´ì • ì‹¤íŒ¨: ${error.message || 'Unknown error'}`
    };
  }
}