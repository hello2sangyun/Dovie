import OpenAI from "openai";
import fs from "fs";

// the newest OpenAI model is "gpt-4o" which was released May 13, 2024. do not change this unless explicitly requested by the user
const openai = new OpenAI({ 
  apiKey: process.env.OPENAI_API_KEY,
  timeout: 30000 // 30 second timeout
});

// Test if API key is available
if (!process.env.OPENAI_API_KEY) {
  console.error("OPENAI_API_KEY environment variable is not set");
} else {
  console.log("OpenAI API key is configured");
}

export interface CommandResponse {
  success: boolean;
  content: string;
  type: 'text' | 'json';
}

// /translate command - translate text to specified language
export async function translateText(text: string, targetLanguage: string = 'English'): Promise<CommandResponse> {
  try {
    console.log(`Attempting translation: "${text}" to ${targetLanguage}`);
    
    const response = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [
        {
          role: "system",
          content: `You are a professional translator. Translate the following text to ${targetLanguage}. Only return the translated text, nothing else.`
        },
        {
          role: "user",
          content: text
        }
      ],
      max_tokens: 1000,
    });

    console.log("OpenAI response received successfully");
    return {
      success: true,
      content: response.choices[0].message.content || "Translation failed",
      type: 'text'
    };
  } catch (error: any) {
    console.error("Translation error details:", {
      message: error.message,
      status: error.status,
      code: error.code,
      type: error.type,
      error: error
    });
    
    return {
      success: false,
      content: `Translation failed: ${error.message || 'Unknown error'}`,
      type: 'text'
    };
  }
}

// /calculate command - perform mathematical calculations using JavaScript eval
export async function calculateExpression(expression: string): Promise<CommandResponse> {
  try {
    // ë³´ì•ˆì„ ìœ„í•´ í—ˆìš©ëœ ë¬¸ìë§Œ í•„í„°ë§
    const sanitizedExpression = expression.replace(/[^0-9+\-*/.() ]/g, '');
    
    if (sanitizedExpression !== expression) {
      return {
        success: false,
        content: "Invalid characters in expression. Only numbers, +, -, *, /, (, ), and spaces are allowed.",
        type: 'text'
      };
    }

    // ë¹ˆ í‘œí˜„ì‹ ì²´í¬
    if (!sanitizedExpression.trim()) {
      return {
        success: false,
        content: "Please provide a mathematical expression to calculate.",
        type: 'text'
      };
    }

    // JavaScriptì˜ evalì„ ì‚¬ìš©í•˜ì—¬ ê³„ì‚° (ë³´ì•ˆìƒ sanitizedëœ ì…ë ¥ë§Œ ì‚¬ìš©)
    const result = eval(sanitizedExpression);
    
    // ê²°ê³¼ê°€ ìœ íš¨í•œ ìˆ«ìì¸ì§€ í™•ì¸
    if (typeof result !== 'number' || isNaN(result)) {
      return {
        success: false,
        content: "Invalid mathematical expression.",
        type: 'text'
      };
    }

    // ìˆ«ì í¬ë§·íŒ… (í° ìˆ«ìëŠ” ì½¤ë§ˆ ì¶”ê°€)
    const formattedResult = result.toLocaleString();

    return {
      success: true,
      content: formattedResult,
      type: 'text'
    };
  } catch (error) {
    return {
      success: false,
      content: "Error calculating expression. Please check your syntax.",
      type: 'text'
    };
  }
}

// /summarize command - summarize text
export async function summarizeText(text: string): Promise<CommandResponse> {
  try {
    const response = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [
        {
          role: "system",
          content: "You are a text summarizer. Provide a concise summary of the following text. Keep it brief and capture the main points."
        },
        {
          role: "user",
          content: text
        }
      ],
      max_tokens: 300,
    });

    return {
      success: true,
      content: response.choices[0].message.content || "Summarization failed",
      type: 'text'
    };
  } catch (error) {
    return {
      success: false,
      content: "Summarization service unavailable",
      type: 'text'
    };
  }
}

// /vibe command - analyze sentiment/vibe of text
export async function analyzeVibe(text: string): Promise<CommandResponse> {
  try {
    const response = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [
        {
          role: "system",
          content: "You are a sentiment analyzer. Analyze the vibe/sentiment of the text and provide a rating from 1-5 stars and describe the emotional tone. Respond with JSON in this format: { 'rating': number, 'emotion': string, 'description': string }"
        },
        {
          role: "user",
          content: text
        }
      ],
      response_format: { type: "json_object" },
      max_tokens: 200,
    });

    const result = JSON.parse(response.choices[0].message.content || '{}');
    const stars = 'â­'.repeat(Math.max(1, Math.min(5, result.rating || 3)));
    
    return {
      success: true,
      content: `${stars} ${result.emotion || 'Neutral'}\n${result.description || 'Unable to analyze sentiment'}`,
      type: 'text'
    };
  } catch (error) {
    return {
      success: false,
      content: "Vibe analysis service unavailable",
      type: 'text'
    };
  }
}

// /poll command - create a poll
export async function createPoll(question: string, options: string[]): Promise<CommandResponse> {
  try {
    if (options.length < 2) {
      return {
        success: false,
        content: "Poll needs at least 2 options. Format: /poll Question? Option1,Option2,Option3",
        type: 'text'
      };
    }

    const pollData = {
      question: question.trim(),
      options: options.map((opt, index) => ({
        id: index + 1,
        text: opt.trim(),
        votes: 0
      })),
      totalVotes: 0,
      createdAt: new Date().toISOString()
    };

    return {
      success: true,
      content: JSON.stringify(pollData),
      type: 'json'
    };
  } catch (error) {
    return {
      success: false,
      content: "Failed to create poll",
      type: 'text'
    };
  }
}

// Command parser to handle different command types
export async function processCommand(commandText: string): Promise<CommandResponse> {
  const parts = commandText.trim().split(' ');
  const command = parts[0].toLowerCase();
  const args = parts.slice(1).join(' ');

  switch (command) {
    case '/translate':
      const translateParts = args.split(' to ');
      if (translateParts.length === 2) {
        return translateText(translateParts[0], translateParts[1]);
      }
      return translateText(args);

    case '/calculate':
    case '/calc':
      return calculateExpression(args);

    case '/summarize':
      return summarizeText(args);

    case '/vibe':
      return analyzeVibe(args);

    case '/poll':
      const pollParts = args.split('?');
      if (pollParts.length !== 2) {
        return {
          success: false,
          content: "Poll format: /poll Question? Option1,Option2,Option3",
          type: 'text'
        };
      }
      const question = pollParts[0] + '?';
      const options = pollParts[1].split(',').map(opt => opt.trim()).filter(opt => opt.length > 0);
      return createPoll(question, options);

    default:
      return {
        success: false,
        content: `Unknown command: ${command}\n\nAvailable commands:\n/translate [text] (to [language])\n/calculate [expression]\n/summarize [text]\n/vibe [text]\n/poll [question]? [option1,option2,option3]`,
        type: 'text'
      };
  }
}

// Audio transcription for voice messages with integrated smart suggestions
export async function transcribeAudio(filePath: string): Promise<{ 
  success: boolean, 
  transcription?: string, 
  duration?: number, 
  detectedLanguage?: string,
  confidence?: number,
  smartSuggestions?: any[],
  error?: string 
}> {
  try {
    console.log("Starting audio transcription with language detection...");
    console.log("Audio file path:", filePath);
    
    // Read file as buffer and create FormData with proper filename
    const audioBuffer = fs.readFileSync(filePath);
    console.log("Audio buffer read successfully, size:", audioBuffer.length, "bytes");
    
    // Create a Blob with proper MIME type and filename
    const audioBlob = new Blob([audioBuffer], { type: "audio/webm" });
    console.log("Audio blob created with type audio/webm");
    
    // Create FormData for OpenAI API with proper filename
    const formData = new FormData();
    formData.append("file", audioBlob, "audio.webm");
    formData.append("model", "whisper-1");
    formData.append("response_format", "verbose_json");
    
    console.log("FormData prepared for OpenAI API");
    
    // Make direct fetch request to OpenAI API
    const response = await fetch("https://api.openai.com/v1/audio/transcriptions", {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${process.env.OPENAI_API_KEY}`,
      },
      body: formData
    });
    
    if (!response.ok) {
      const errorText = await response.text();
      console.error("OpenAI API Error:", response.status, errorText);
      
      // Handle audio too short error as silent recording
      if (errorText.includes("Audio file is too short") || errorText.includes("audio_too_short")) {
        console.log("ğŸ”‡ Audio file too short, treating as silent recording");
        return {
          text: "",
          language: "ko",
          duration: 0,
          confidence: 0,
          error: "SILENT_RECORDING"
        };
      }
      
      throw new Error(`OpenAI API Error: ${response.status} ${errorText}`);
    }
    
    const transcription = await response.json();
    console.log("Direct API call successful");

    console.log("Audio transcription completed:", {
      text: transcription.text,
      language: transcription.language,
      duration: transcription.duration
    });
    
    // Map language codes to readable names
    const languageNames: { [key: string]: string } = {
      'ko': 'í•œêµ­ì–´',
      'en': 'English', 
      'hu': 'Magyar',
      'de': 'Deutsch',
      'ja': 'æ—¥æœ¬èª',
      'zh': 'ä¸­æ–‡',
      'es': 'EspaÃ±ol',
      'fr': 'FranÃ§ais',
      'it': 'Italiano',
      'pt': 'PortuguÃªs',
      'ru': 'Ğ ÑƒÑÑĞºĞ¸Ğ¹'
    };
    
    const detectedLanguage = languageNames[transcription.language] || transcription.language;
    const transcribedText = transcription.text || "";
    
    // Check if transcription contains meaningful content
    const isEmptyOrNoise = (text: string): boolean => {
      if (!text || text.trim().length === 0) return true;
      
      // Common noise patterns and meaningless transcriptions
      const noisePatterns = [
        /^[\s.,!?]*$/,  // Only punctuation and whitespace
        /^(um|uh|ah|eh|hmm|mm|ì•„|ì–´|ìŒ|ìœ¼|ì•„ìš°|ì–´ìš°|ìŒ\.\.\.|\.\.\.)+[\s.,!?]*$/i,  // Filler sounds
        /^[\uD83C-\uDBFF\uDC00-\uDFFF]+[\s.,!?]*$/,  // Only emojis
        /^[ğŸ“¢ğŸµğŸ¤ğŸ”ŠğŸ”‡ğŸ“»]+[\s.,!?]*$/,  // Audio/sound emojis
        /thank you|ê°ì‚¬í•©ë‹ˆë‹¤|ê³ ë§ˆì›Œ|sorry|ì£„ì†¡|ë¯¸ì•ˆ/i  // Common polite expressions that might be background audio
      ];
      
      // Check text length (very short transcriptions are likely noise)
      if (text.trim().length < 3) return true;
      
      // Check against noise patterns
      return noisePatterns.some(pattern => pattern.test(text.trim()));
    };
    
    // If transcription is empty or just noise, return cancellation response
    if (isEmptyOrNoise(transcribedText)) {
      console.log("ğŸ”‡ Voice recording contains no meaningful speech, canceling message");
      return {
        success: false,
        transcription: "",
        error: "SILENT_RECORDING", // Special error code for silent recordings
        duration: transcription.duration || 0,
        detectedLanguage,
        confidence: 0,
        smartSuggestions: []
      };
    }
    
    // Analyze transcribed text for smart suggestions using a single OpenAI call
    let smartSuggestions: any[] = [];
    if (transcribedText && transcribedText.length > 5) {
      console.log("ğŸ¤– Analyzing transcription for smart suggestions:", transcribedText);
      
      try {
        const analysisResponse = await openai.chat.completions.create({
          model: "gpt-4o", // the newest OpenAI model is "gpt-4o" which was released May 13, 2024. do not change this unless explicitly requested by the user
          messages: [
            {
              role: "system",
              content: `ë‹¹ì‹ ì€ ìŒì„± ë©”ì‹œì§€ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•´ì„œ ì‚¬ìš©ìê°€ ì›í•˜ëŠ” í–‰ë™ì„ íŒŒì•…í•˜ëŠ” AIì…ë‹ˆë‹¤. 
              ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ ì¤‘ì—ì„œ í•´ë‹¹í•˜ëŠ” ê²ƒì„ ì°¾ì•„ JSONìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
              
              1. youtube: ìœ íŠœë¸Œ ì˜ìƒ ê²€ìƒ‰/ì¶”ì²œ (ì˜ˆ: "ì§€ë“œë˜ê³¤ ìœ íŠœë¸Œ", "ìƒë‚¨ì ì˜ìƒ", "ìœ íŠœë¸Œë¡œ ê²€ìƒ‰", "ì˜ìƒ ë´ë´")
              2. location: ìœ„ì¹˜ ê³µìœ /ë¬¸ì˜ (ì˜ˆ: "ì–´ë””ì•¼", "ì£¼ì†Œ ì•Œë ¤ì¤˜", "ì–´ë””ë¡œ ê°€ë©´ ë¼")
              3. translation: ë²ˆì—­ ìš”ì²­ (ì˜ˆ: "ì˜ì–´ë¡œ", "í•œêµ­ì–´ë¡œ", "ë²ˆì—­í•´ì¤˜")
              4. search: ê²€ìƒ‰ ìš”ì²­ (ì˜ˆ: "ê²€ìƒ‰í•´ì¤˜", "ì°¾ì•„ë´")
              5. calculation: ê³„ì‚° ìš”ì²­ (ì˜ˆ: "ê³„ì‚°í•´ì¤˜", "ì–¼ë§ˆì•¼")
              6. currency: í™˜ìœ¨ ê³„ì‚° (ì˜ˆ: "ë‹¬ëŸ¬", "ì›", "í™˜ìœ¨")
              7. news: ë‰´ìŠ¤/ì •ë³´ (ì˜ˆ: "ë‰´ìŠ¤", "ì†Œì‹", "ì •ë³´")
              
              ì‘ë‹µ í˜•ì‹:
              {
                "suggestions": [
                  {
                    "type": "youtube",
                    "keyword": "ì¶”ì¶œëœ í‚¤ì›Œë“œ",
                    "confidence": 0.9,
                    "text": "ğŸ¥ YouTubeì—ì„œ [í‚¤ì›Œë“œ] ê²€ìƒ‰í•˜ê¸°",
                    "icon": "ğŸ¥"
                  }
                ]
              }
              
              YouTubeì˜ ê²½ìš° ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì •í™•íˆ ì¶”ì¶œí•˜ì„¸ìš”.
              ë§¤ì¹­ë˜ëŠ” ê²ƒì´ ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´ì„ ë°˜í™˜í•˜ì„¸ìš”.`
            },
            {
              role: "user",
              content: transcribedText
            }
          ],
          response_format: { type: "json_object" }
        });
        
        const analysisResult = JSON.parse(analysisResponse.choices[0].message.content || '{"suggestions":[]}');
        smartSuggestions = analysisResult.suggestions || [];
        
        console.log("ğŸ¤– Smart suggestions analysis completed:", smartSuggestions.length, "suggestions");
        
      } catch (analysisError) {
        console.error("Smart suggestions analysis failed:", analysisError);
        // Continue without suggestions rather than failing the whole transcription
      }
    }
    
    return {
      success: true,
      transcription: transcribedText,
      duration: transcription.duration || 0,
      detectedLanguage,
      confidence: 0.9, // Whisper doesn't provide confidence scores, but it's generally reliable
      smartSuggestions
    };
  } catch (error: any) {
    console.error("Audio transcription error:", {
      message: error.message,
      status: error.status,
      code: error.code,
      type: error.type,
      error: error
    });
    
    return {
      success: false,
      error: `ìŒì„± ë³€í™˜ ì‹¤íŒ¨: ${error.message || 'Unknown error'}`
    };
  }
}

// íŒŒì¼ ìš”ì•½ ìƒì„± í•¨ìˆ˜
export async function generateFileSummary(fileName: string, fileType: string, fileContent?: string): Promise<string> {
  try {
    console.log(`Generating file summary for: ${fileName} (${fileType})`);
    
    let prompt = `ë‹¤ìŒ íŒŒì¼ì— ëŒ€í•œ ì•„ì£¼ ê°„ë‹¨í•œ ìš”ì•½ì„ í•œ ì¤„ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”. 15ì ì´ë‚´ë¡œ í•µì‹¬ ë‚´ìš©ë§Œ ì„¤ëª…í•˜ì„¸ìš”.
íŒŒì¼ëª…: ${fileName}
íŒŒì¼ ìœ í˜•: ${fileType}`;

    if (fileContent) {
      prompt += `\níŒŒì¼ ë‚´ìš©: ${fileContent.substring(0, 1000)}...`;
    }

    const response = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [
        {
          role: "system",
          content: "ë‹¹ì‹ ì€ íŒŒì¼ ë‚´ìš©ì„ ê°„ë‹¨íˆ ìš”ì•½í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 15ì ì´ë‚´ë¡œ í•µì‹¬ë§Œ ì„¤ëª…í•˜ì„¸ìš”."
        },
        {
          role: "user",
          content: prompt
        }
      ],
      max_tokens: 30,
      temperature: 0.3
    });

    const summary = response.choices[0].message.content?.trim() || "íŒŒì¼";
    console.log(`File summary generated: "${summary}"`);
    
    return summary;
  } catch (error: any) {
    console.error("File summary generation error:", error);
    
    // íŒŒì¼ í™•ì¥ìë¡œ ê¸°ë³¸ ì„¤ëª… ì œê³µ
    const extension = fileName.split('.').pop()?.toLowerCase();
    switch (extension) {
      case 'pdf': return 'PDF ë¬¸ì„œ';
      case 'doc':
      case 'docx': return 'Word ë¬¸ì„œ';
      case 'xls':
      case 'xlsx': return 'Excel íŒŒì¼';
      case 'ppt':
      case 'pptx': return 'PPT íŒŒì¼';
      case 'txt': return 'í…ìŠ¤íŠ¸ íŒŒì¼';
      case 'jpg':
      case 'jpeg':
      case 'png':
      case 'gif': return 'ì´ë¯¸ì§€';
      case 'mp4':
      case 'avi':
      case 'mov': return 'ë™ì˜ìƒ';
      case 'mp3':
      case 'wav': return 'ìŒì„± íŒŒì¼';
      case 'zip':
      case 'rar': return 'ì••ì¶• íŒŒì¼';
      default: return 'íŒŒì¼';
    }
  }
}