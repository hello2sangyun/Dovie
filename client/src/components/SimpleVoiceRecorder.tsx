import React, { useState, useRef, useEffect, useImperativeHandle, forwardRef } from 'react';
import { Mic, MicOff } from 'lucide-react';

interface SimpleVoiceRecorderProps {
  onRecordingComplete: (audioBlob: Blob, duration: number) => void;
  onComplete?: (audioBlob: Blob, duration: number) => void;
  onCancel?: () => void;
  disabled?: boolean;
  autoStart?: boolean;
  shouldStop?: boolean;
}

export interface SimpleVoiceRecorderRef {
  stopRecording: () => void;
}

const SimpleVoiceRecorder = forwardRef<SimpleVoiceRecorderRef, SimpleVoiceRecorderProps>((props, ref) => {
  const { 
    onRecordingComplete, 
    onComplete, 
    onCancel, 
    disabled, 
    autoStart = false,
    shouldStop = false
  } = props;
  const [isRecording, setIsRecording] = useState(false);
  const [isPreparing, setIsPreparing] = useState(false);
  const [duration, setDuration] = useState(0);
  const [microphoneAccess, setMicrophoneAccess] = useState(false);

  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const chunksRef = useRef<Blob[]>([]);
  const startTimeRef = useRef<number>(0);
  const timerRef = useRef<NodeJS.Timeout | null>(null);

  // Expose stopRecording method via ref
  useImperativeHandle(ref, () => ({
    stopRecording: () => {
      if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
        console.log('ğŸ”´ Stopping recording via ref');
        mediaRecorderRef.current.stop();
      }
    }
  }));

  useEffect(() => {
    return () => {
      cleanup();
    };
  }, []);

  // Auto-start recording when component mounts
  useEffect(() => {
    if (autoStart && !isRecording && !isPreparing) {
      startRecording();
    }
  }, [autoStart]);

  // Handle external stop signal
  useEffect(() => {
    if (shouldStop && isRecording) {
      stopRecording();
    }
  }, [shouldStop, isRecording]);

  const cleanup = () => {
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
      streamRef.current = null;
    }
    
    if (mediaRecorderRef.current) {
      // Clean up data request interval
      if ((mediaRecorderRef.current as any).dataInterval) {
        clearInterval((mediaRecorderRef.current as any).dataInterval);
      }
      mediaRecorderRef.current = null;
    }
    
    if (timerRef.current) {
      clearInterval(timerRef.current);
      timerRef.current = null;
    }
    
    setDuration(0);
    setIsRecording(false);
    setIsPreparing(false);
  };

  const startRecording = async () => {
    if (disabled) return;
    
    console.log('ğŸ¤ SimpleVoiceRecorder: Starting recording process...');
    console.log('ğŸ¤ Browser support check:', {
      mediaDevices: !!navigator.mediaDevices,
      getUserMedia: !!navigator.mediaDevices?.getUserMedia,
      MediaRecorder: !!window.MediaRecorder
    });
    
    // Test MIME type support
    const testTypes = ['audio/webm;codecs=opus', 'audio/webm', 'audio/ogg;codecs=opus', 'audio/mp4'];
    testTypes.forEach(type => {
      console.log(`ğŸ¤ MIME type ${type}: ${MediaRecorder.isTypeSupported(type)}`);
    });
    
    setIsPreparing(true);
    
    try {
      // Check microphone permissions first
      try {
        const permissionStatus = await navigator.permissions.query({ name: 'microphone' as PermissionName });
        console.log('ğŸ¤ Microphone permission status:', permissionStatus.state);
        
        if (permissionStatus.state === 'denied') {
          throw new Error('ë§ˆì´í¬ ê¶Œí•œì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì—ì„œ ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.');
        }
      } catch (permError) {
        console.log('ğŸ¤ Permission API not available, proceeding with getUserMedia');
      }
      
      // Request microphone access
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
          sampleRate: 44100
        } 
      });
      
      // Verify audio track is working
      const audioTracks = stream.getAudioTracks();
      if (audioTracks.length === 0 || audioTracks[0].readyState !== 'live') {
        throw new Error('ë§ˆì´í¬ì—ì„œ ì˜¤ë””ì˜¤ë¥¼ ë°›ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
      }
      
      console.log('ğŸ¤ Audio track verified:', audioTracks[0].label, 'state:', audioTracks[0].readyState);
      
      console.log('SimpleVoiceRecorder: Microphone access granted');
      streamRef.current = stream;
      setMicrophoneAccess(true);
      
      // Find best supported MIME type
      const supportedTypes = [
        'audio/webm;codecs=opus',
        'audio/webm',
        'audio/ogg;codecs=opus',
        'audio/mp4',
        'audio/wav'
      ];
      
      let selectedMimeType = 'audio/webm';
      for (const type of supportedTypes) {
        if (MediaRecorder.isTypeSupported(type)) {
          selectedMimeType = type;
          console.log('SimpleVoiceRecorder: Using MIME type:', selectedMimeType);
          break;
        }
      }
      
      // Create MediaRecorder
      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: selectedMimeType
      });
      
      mediaRecorderRef.current = mediaRecorder;
      chunksRef.current = [];
      
      // Set up event handlers
      mediaRecorder.ondataavailable = (event) => {
        console.log('ğŸµ SimpleVoiceRecorder: Data chunk received, size:', event.data.size, 'type:', event.data.type);
        console.log('ğŸµ Total chunks so far:', chunksRef.current.length + 1);
        if (event.data && event.data.size > 0) {
          chunksRef.current.push(event.data);
          console.log('ğŸµ Chunk added to array. New total size:', chunksRef.current.reduce((sum, chunk) => sum + chunk.size, 0));
        } else {
          console.warn('âš ï¸ Empty chunk received');
        }
      };
      
      mediaRecorder.onstop = () => {
        console.log('ğŸ›‘ SimpleVoiceRecorder: Recording stopped, processing audio...');
        console.log('ğŸ›‘ Chunks collected:', chunksRef.current.length);
        console.log('ğŸ›‘ Individual chunk sizes:', chunksRef.current.map(chunk => chunk.size));
        
        if (chunksRef.current.length === 0) {
          console.error('âŒ SimpleVoiceRecorder: No audio data recorded');
          cleanup();
          return;
        }
        
        const audioBlob = new Blob(chunksRef.current, { type: selectedMimeType });
        const recordingDuration = Math.max(duration, 1);
        
        console.log('ğŸ¯ SimpleVoiceRecorder: Audio blob created');
        console.log('ğŸ¯ Blob size:', audioBlob.size, 'bytes');
        console.log('ğŸ¯ Blob type:', audioBlob.type);
        console.log('ğŸ¯ Recording duration:', recordingDuration, 'seconds');
        console.log('ğŸ¯ MIME type used:', selectedMimeType);
        
        if (audioBlob.size < 100) {
          console.error('âŒ SimpleVoiceRecorder: Audio file too small:', audioBlob.size, 'bytes');
          console.error('âŒ This usually indicates microphone access issues or short recording time');
          console.error('âŒ Chunks collected:', chunksRef.current.length);
          console.error('âŒ Recording duration was:', recordingDuration, 'seconds');
          cleanup();
          return;
        }
        
        console.log('âœ… Calling onRecordingComplete with valid audio blob');
        onRecordingComplete(audioBlob, recordingDuration);
        
        // Also call onComplete if provided (for compatibility)
        if (onComplete) {
          onComplete(audioBlob, recordingDuration);
        }
        
        cleanup();
      };
      
      mediaRecorder.onerror = (event) => {
        console.error('SimpleVoiceRecorder: MediaRecorder error:', event);
        cleanup();
      };
      
      // Start recording with explicit timeslice for better data collection
      mediaRecorder.start(200); // Request data every 200ms
      startTimeRef.current = Date.now();
      setIsRecording(true);
      setIsPreparing(false);
      
      console.log('ğŸ¤ SimpleVoiceRecorder: Recording started');
      console.log('ğŸ¤ MediaRecorder state:', mediaRecorder.state);
      console.log('ğŸ¤ Stream active:', stream.active);
      console.log('ğŸ¤ Audio tracks:', stream.getAudioTracks().length);
      console.log('ğŸ¤ Audio track settings:', stream.getAudioTracks()[0]?.getSettings());
      
      // Force periodic data requests to ensure we get audio chunks
      const dataRequestInterval = setInterval(() => {
        if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
          try {
            mediaRecorderRef.current.requestData();
            console.log('ğŸ”„ Requested data chunk at', Date.now() - startTimeRef.current, 'ms');
          } catch (e) {
            console.warn('Failed to request data:', e);
          }
        } else {
          clearInterval(dataRequestInterval);
        }
      }, 300);
      
      // Store interval reference for cleanup
      (mediaRecorder as any).dataInterval = dataRequestInterval;
      
      // Start timer
      timerRef.current = setInterval(() => {
        const elapsed = Math.floor((Date.now() - startTimeRef.current) / 1000);
        setDuration(elapsed);
      }, 100);
      
    } catch (error) {
      console.error('SimpleVoiceRecorder: Failed to start recording:', error);
      setMicrophoneAccess(false);
      setIsPreparing(false);
      cleanup();
    }
  };

  const stopRecording = () => {
    if (mediaRecorderRef.current && isRecording) {
      const recordingTime = Date.now() - startTimeRef.current;
      console.log('ğŸ›‘ SimpleVoiceRecorder: Stopping recording after', recordingTime, 'ms');
      console.log('ğŸ›‘ MediaRecorder state before stop:', mediaRecorderRef.current.state);
      
      // Force data collection before stopping
      if (mediaRecorderRef.current.state === 'recording') {
        try {
          mediaRecorderRef.current.requestData();
          console.log('ğŸ›‘ Requested final data chunk');
        } catch (e) {
          console.warn('ğŸ›‘ Failed to request data:', e);
        }
      }
      
      // Ensure minimum recording time of 1 second for meaningful audio
      const minRecordingTime = 1000;
      if (recordingTime < minRecordingTime) {
        console.log('ğŸ›‘ Recording too short, waiting for minimum duration...');
        setTimeout(() => {
          if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
            try {
              // Request final data and stop
              mediaRecorderRef.current.requestData();
              setTimeout(() => {
                if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
                  mediaRecorderRef.current.stop();
                }
              }, 100);
            } catch (e) {
              console.error('ğŸ›‘ Error stopping recorder:', e);
            }
          }
        }, minRecordingTime - recordingTime);
      } else {
        try {
          // Request final data before stopping
          mediaRecorderRef.current.requestData();
          setTimeout(() => {
            if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
              mediaRecorderRef.current.stop();
            }
          }, 100);
        } catch (e) {
          console.error('ğŸ›‘ Error stopping recorder:', e);
        }
      }
      
      setIsRecording(false);
    }
  };

  const handleMouseDown = (e: React.MouseEvent) => {
    e.preventDefault();
    if (!isRecording && !isPreparing) {
      startRecording();
    }
  };

  const handleMouseUp = (e: React.MouseEvent) => {
    e.preventDefault();
    if (isRecording) {
      stopRecording();
    }
  };

  const handleTouchStart = (e: React.TouchEvent) => {
    e.preventDefault();
    if (!isRecording && !isPreparing) {
      startRecording();
    }
  };

  const handleTouchEnd = (e: React.TouchEvent) => {
    e.preventDefault();
    if (isRecording) {
      stopRecording();
    }
  };

  return (
    <div className="flex flex-col items-center justify-center p-4">
      <div
        className={`
          w-20 h-20 rounded-full flex items-center justify-center cursor-pointer
          transition-all duration-200 user-select-none
          ${isRecording 
            ? 'bg-red-500 scale-110 animate-pulse' 
            : isPreparing 
            ? 'bg-yellow-500' 
            : disabled
            ? 'bg-gray-400 cursor-not-allowed'
            : 'bg-blue-500 hover:bg-blue-600 active:scale-95'
          }
        `}
        onMouseDown={handleMouseDown}
        onMouseUp={handleMouseUp}
        onMouseLeave={handleMouseUp}
        onTouchStart={handleTouchStart}
        onTouchEnd={handleTouchEnd}
        style={{
          WebkitUserSelect: 'none',
          MozUserSelect: 'none',
          msUserSelect: 'none',
          userSelect: 'none',
          WebkitTouchCallout: 'none'
        }}
      >
        {isPreparing ? (
          <div className="animate-spin w-8 h-8 border-2 border-white border-t-transparent rounded-full" />
        ) : isRecording ? (
          <MicOff className="w-8 h-8 text-white" />
        ) : (
          <Mic className="w-8 h-8 text-white" />
        )}
      </div>
      
      {isRecording && (
        <div className="mt-2 text-sm text-gray-600">
          ë…¹ìŒ ì¤‘... {duration}ì´ˆ
        </div>
      )}
      
      {isPreparing && (
        <div className="mt-2 text-sm text-gray-600">
          ë§ˆì´í¬ ì¤€ë¹„ ì¤‘...
        </div>
      )}
    </div>
  );
});

SimpleVoiceRecorder.displayName = 'SimpleVoiceRecorder';

export default SimpleVoiceRecorder;